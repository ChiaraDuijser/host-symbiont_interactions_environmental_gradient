---
title: "Photobiology analysis (October 2022; Low Isles)"
author: "Chiara Duijser, Matthew Nitschke"
date: "2023-06-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries
```{r}
# Libraries for plotting and being tidy
library(tidyverse)
library(broom)
library(purrr)
library(lubridate)
theme_set(theme_bw())

# Libraries for fitting curves
library(nls.multstart)
library(nlstools)
library(bestNormalize)
library(vegan)
library(ggalt)

# Additional
library(ggfortify)
library(ggalt)
library(RColorBrewer)
library("factoextra")
library(car)
library(rstatix)
library(magrittr)
```

# Photobiology data import
```{r message = FALSE, warning = FALSE}
file_names <- list.files(getwd(), pattern = "_fit.csv", full.names = TRUE, recursive = TRUE)
file_paths <- file.path(file_names)

combined_data <- file_paths %>%
  map(read_csv) %>% # read in all the files, using the function read_csv() from the readr package
  map(select, `Source DataFile`:QBP_Size) %>%
  purrr::reduce(rbind) %>%      # reduce with rbind into one dataframe
  filter(!str_detect(DATE, "---")) %>% # Remove the pointless line below the column names
  dplyr::rename(sample_filename = `Source DataFile`) # Make column header R friendly
```

# Create metadata
```{r}
c_meta <- read_csv("chiara_metadata.csv") %>%
  mutate(across(where(is.numeric), as.character)) %>%
  mutate(site = case_when(site == "1" ~ "mangrove_1",
                          site == "2" ~ "mangrove_2",
                          site == "3" ~ "reef_3",
                          site == "4" ~ "reef_4"))

#c_meta with added sample_filename
meta <- data.frame(sample_filename = unique(combined_data$sample_filename)) %>%
   mutate(sample_id = paste0(str_remove_all(sample_filename, "\\\\"))) %>%
    mutate(sample_id = paste0(str_remove_all(sample_id, "C:LIFTDATAChiara Oct 2022"))) %>%
        mutate(sample_id = paste0(str_remove_all(sample_id, "_data.csv"))) %>%
          left_join(., c_meta)
```

# Join metadata in with data values
```{r}
all_data <- left_join(combined_data, meta) %>%
  dplyr::rename(PAR = Light_1, FqFm = `Fv/Fm`) 
write_csv(all_data, "all_soliense_data.csv")

all_data <- read_csv("all_soliense_data.csv")
all_data$SigLCHII <- ((all_data$Sig) / (all_data$FqFm)) # produce SigmaLCHII as in Suggett et al. 2022
```

# Select only the RLC data, tidy the PAR values, and create some grouping factors
```{r}
data_rlc <- all_data %>%
  group_by(sample_filename) %>%
  slice_head(n = 31) %>%
  mutate(PAR = floor(as.numeric(PAR)),
         PAR = ifelse(PAR < 1, 0.1, PAR)) %>% # PAR values = 0 will result in infinite values during fitting. Replace with 0.1.
  type_convert() %>%
  mutate(PAR_factor = factor(as.character(PAR))) %>% # Create a categorical PAR variable
  mutate(PAR_factor = fct_relevel(PAR_factor, "0.1", "10", "25", "50", "100", "150", "250", "500", "750", "1000", "1250")) %>%
  group_by(sample_filename) %>%
  mutate(measurement = row_number(), # Create a measurement index
         curve_id = group_indices()) %>% # Create a curve index
  ungroup()
```

# Average the yields at each PAR step
```{r}
data_means <- data_rlc %>%
  group_by(sample_filename, DATE, PAR, PAR_factor, curve_id, sample_id, site, colony, habitat) %>%
  summarise(Fo = mean(Fo), #F0 = minimum fluorescence; PSII reaction centers open in dark-adapted state
            Fm = mean(Fm)) %>% #Fm = maximum fluorescence; closed state of PSII reaction centers
  ungroup()

# Perform sanity check for expected numbers of measurements
sanity <- data_means %>%
  group_by(PAR_factor) %>%
  dplyr::count()
```
  
# Investigate the other parameters generated by the Soliense
All remaining analysis is performed for PAR = 0.1
```{r}
 dark_params <- data_rlc %>%
  filter(PAR == 0.1) %>%
  select(sample_id, curve_id, site, colony, habitat, FqFm, Sig, PQP_Size, Tau1QA, Tau2QA, Tau3QA, p, TPQ_PSI, QBP_Size, carQ, Ek, SigLCHII) %>% 
  pivot_longer(FqFm:SigLCHII, names_to = "params", values_to = "value")
 
ggplot(dark_params, aes(site, value)) +
  geom_boxplot(aes(fill = habitat)) +
  facet_wrap(~params, scales = "free_y") +
  scale_fill_manual(values = c("black", "yellow"))
```

# Check for outliers within each level of params and remove if present
Mahalanobis Distance works well when two or more variables are highly correlated and even if their scales are not the same, because MD uses a covariance matrix (unlike Euclidean Distance).
```{r}
#select data within dataset; carQ
dark_params_carQ <- dark_params %>%
                          filter(params == "carQ")

# Compute mahalonobis distance and flag outliers if any
dark_params_carQ %>%
  doo(~mahalanobis_distance(dark_params_carQ, value)) %>%
  filter(is.outlier==T)

#select data within dataset; Ek
dark_params_Ek <- dark_params %>%
                          filter(params == "Ek")

# Compute mahalonobis distance and flag outliers if any
dark_params_Ek %>%
  doo(~mahalanobis_distance(dark_params_Ek, value)) %>%
  filter(is.outlier==T)

#select data within dataset; FqFm
dark_params_FqFm <- dark_params %>%
                          filter(params == "FqFm")

# Compute mahalonobis distance and flag outliers if any
dark_params_FqFm %>%
  doo(~mahalanobis_distance(dark_params_FqFm, value)) %>%
  filter(is.outlier==T)

#select data within dataset; PQP_size
dark_params_PQP_Size <- dark_params %>%
                          filter(params == "PQP_Size")

# Compute mahalonobis distance and flag outliers if any
dark_params_PQP_Size %>%
  doo(~mahalanobis_distance(dark_params_PQP_Size, value)) %>%
  filter(is.outlier==T)

#select data within dataset; QBP_Size
dark_params_QBP_Size <- dark_params %>%
                          filter(params == "QBP_Size")

# Compute mahalonobis distance and flag outliers if any
dark_params_QBP_Size %>%
  doo(~mahalanobis_distance(dark_params_QBP_Size, value)) %>%
  filter(is.outlier==T)

#select data within dataset; Sig
dark_params_Sig <- dark_params %>%
                          filter(params == "Sig")

# Compute mahalonobis distance and flag outliers if any
dark_params_Sig %>%
  doo(~mahalanobis_distance(dark_params_Sig, value)) %>%
  filter(is.outlier==T)

#select data within dataset; Tau1QA
dark_params_Tau1QA <- dark_params %>%
                          filter(params == "Tau1QA")

# Compute mahalonobis distance and flag outliers if any
dark_params_Tau1QA %>%
  doo(~mahalanobis_distance(dark_params_Tau1QA, value)) %>%
  filter(is.outlier==T)

#select data within dataset; Tau2QA
dark_params_Tau2QA <- dark_params %>%
                          filter(params == "Tau2QA")

# Compute mahalonobis distance and flag outliers if any
dark_params_Tau2QA %>%
  doo(~mahalanobis_distance(dark_params_Tau2QA, value)) %>%
  filter(is.outlier==T)

#select data within dataset; Tau3QA
dark_params_Tau3QA <- dark_params %>%
                          filter(params == "Tau3QA")

# Compute mahalonobis distance and flag outliers if any
dark_params_Tau3QA %>%
  doo(~mahalanobis_distance(dark_params_Tau3QA, value)) %>%
  filter(is.outlier==T)

#select data within dataset; TPQ_PSI
dark_params_TPQ_PSI <- dark_params %>%
                          filter(params == "TPQ_PSI")

# Compute mahalonobis distance and flag outliers if any
dark_params_TPQ_PSI %>%
  doo(~mahalanobis_distance(dark_params_TPQ_PSI, value)) %>%
  filter(is.outlier==T)

#select data within dataset; SigLCHII
dark_params_SigLCHII <- dark_params %>%
                          filter(params == "SigLCHII")

# Compute mahalonobis distance and flag outliers if any
dark_params_SigLCHII %>%
  doo(~mahalanobis_distance(dark_params_TPQ_PSI, value)) %>%
  filter(is.outlier==T)
```

Based on mahalanobis_distance separated by group, only curve_id 14 is considered an outlier and belongs to the inner mangrove. Let's remove these data points from dark_params

```{r}
dark_params <- data_rlc %>% #data_rlc already has metadata in last columns
  filter(PAR == 0.1) %>%
  select(sample_id, curve_id, site, colony, habitat, FqFm, Sig, PQP_Size, Tau1QA, Tau2QA, Tau3QA, p, TPQ_PSI, QBP_Size, carQ, Ek, SigLCHII) 

dark_params_NOut <- subset(dark_params, curve_id!=14)
dark_params_NOut$sample_id <- as.factor(dark_params_NOut$sample_id)
dark_params_NOut$site <- as.factor(dark_params_NOut$site)
```

Outliers are removed. Now, it's important to normalize our data before making a PCA plot. 

# Do multivariate analysis of the Soliense parameters (outliers removed)
```{r}
# Remove p due to constant number which will cause trouble later on if included
dark_params_NOut <- dark_params_NOut[,!names(dark_params_NOut) %in% "p"]
  
### Normalization ###
# apply bestNormalize heuristics
  params_bns <- dark_params_NOut 

  inst_transformations <- data.frame()
  for(i in 6:ncol(params_bns)){ 
  set.seed(3455)
  dat <- params_bns %>% pull(i)
  whichnorm <- bestNormalize(dat, standardize = FALSE, out_of_sample = FALSE)
  #print(colnames(params_bns[i]))
  #print(whichnorm)
  params_bns[i] <- whichnorm$x.t
  
  trans <- data.frame(variable = colnames(params_bns[i]), transformation = class(whichnorm$chosen_transform))
  inst_transformations <- rbind(inst_transformations, trans)
  }
  
  rda <- params_bns %>%
  column_to_rownames(var = "sample_id") %>% 
  select(PQP_Size:SigLCHII) #leave FqFm and Sig out because we use SigmaLCHII
  
# zero mean
rda <- vegan::decostand(rda, method = "standardize") # make zero mean

# pca
pca <- rda(rda)

# extract the scores
scrs_samples <- as.data.frame(scores(pca, display = "sites")) %>% # Extract sample scores
  rownames_to_column(var = "sample_id")
scrs_params <- as.data.frame(scores(pca, display = "species")) %>% # Extract parameter scores; PCA coordinates
  rownames_to_column(var = "dark_params_NOut")

# create plot dataframe
dark_params_NOut$curve_id <- as.character(dark_params_NOut$curve_id)
plot_df <- left_join(dark_params_NOut, scrs_samples) #column sample_id in common; will be the first column in new dataset

(p <- ggplot(plot_df, aes(x = PC1, y = PC2)) +
  geom_point(aes(fill = site, color=site), size = 4, alpha=1.0) +
  geom_segment(data = scrs_params, aes(x = 0, xend = PC1, y = 0, yend = PC2), 
               size = 0.5, arrow = arrow(length = unit(0.25, "cm")), colour = "grey") +
  geom_text(data = scrs_params, aes(x = PC1, y = PC2, label = dark_params_NOut), size = 4) +
    geom_text(label=dark_params_NOut$sample_id, nudge_x=0, nudge_y=-0.15, check_overlap=T) +
  scale_fill_manual(values = c("green", "blue")) +
  scale_color_manual(values = c("green", "blue")) +
  ggalt::geom_encircle(aes(fill = site), s_shape = 1, expand = 0, alpha = 0.2, show.legend = F) +
  theme(legend.position = "right", aspect.ratio = 1) +
  guides(fill = guide_legend(override.aes = list(shape = 21))))
```

Homogeneity of variance around group centroid is something we test in PERMANOVA but necessarily for PCA.

# Update aesthetics of PCA
```{r}
df <- params_bns %>%
      select(PQP_Size:SigLCHII)
pca_2 <- prcomp(df, scale=T) #scale=T gives error, because p is constant, make sure p is removed from dataset. Already done above!

# Figure 3
(PCA0.1 <- autoplot(pca_2, data = params_bns, colour = "site", shape = "site", size=2, loadings = TRUE, loadings.colour = 'black', loadings.label = TRUE, loadings.label.size = 4, loadings.label.colour = 'black', loadings.label.repel=T) + 
  geom_encircle(aes(group=site, colour=site, fill=site), alpha=0.4, s_shape=1, expand=0) +
  #geom_text(label=params_bns$sample_id, nudge_x=0.025, check_overlap=T) +
  scale_colour_manual(
    name="Site", 
    breaks=c("reef_4", "mangrove_1" ), 
    values=c("#1F78B4", "#33A02C"), 
    labels=c("Outer reef", "Inner mangrove")) +
  scale_fill_manual(
    values=c("#1F78B4", "#33A02C"),
    name="Site", 
    breaks=c("reef_4", "mangrove_1" ), 
    labels=c("Outer reef", "Inner mangrove")) +
  scale_shape_discrete(
    name="Site", 
    breaks=c("reef_4", "mangrove_1" ), 
    labels=c("Outer reef", "Inner mangrove")) +
  theme_bw() +
    theme(axis.title.x = element_text(size=12, face="bold"),
    axis.title.y = element_text(size=12, face="bold"),
    legend.title = element_text(size=12, face="bold"),
    legend.text = element_text(size=12, face="italic"),
    axis.text.x= element_text(colour="black", size=10),
    axis.text.y = element_text(colour="black", size=10),
    legend.background = element_blank(),
    legend.box.background = element_rect(colour = "black"),
    legend.position = c(0.85, 0.15)))
#ggsave("PCA_SigLCH.pdf", width=9, height=5)
```

### Extracting data from PCA
```{r}
#Eigenvalues
eig.val_Dp <- get_eigenvalue(pca_2)
eig.val_Dp
# Results for Variables
res.var_Dp <- get_pca_var(pca_2)
res.var_Dp$coord          # Coordinates
res.var_Dp$contrib        # Contributions to the PCs
res.var_Dp$cos2           # Quality of representation 

#export Dim.1 and Dim.2 as csv
c_Dp <- res.var_Dp$contrib[, c("Dim.1", "Dim.2")]
head(c_Dp)
#write.csv(c_Dp, file = paste0(LIFT_Statistics, "PCAvarcontrib_DarkParams_SigLCHII", Sys.Date(), ".csv"))

#Extract results for individuals
res.ind_Dp <- get_pca_ind(pca_2)
res.ind_Dp$coord          # Coordinates
res.ind_Dp$contrib        # Contributions to the PCs
res.ind_Dp$cos2  # Quality of representation

# export Dim.1 and Dim.2 as csv. Note: Sys.Date() adds the date the file was made at the end of your file name
# This will export res.ind$coord -> change this if you want to export one of the other extracted results above
d_Dp <- res.ind_Dp$coord[, c("Dim.1", "Dim.2")]
head(d_Dp)
#write.csv(d_Dp, file = paste0(LIFT_Statistics, "PCAindcoor_DarkParams_SigLCHII", Sys.Date(), ".csv"))
```


### Statistical analysis on PC1 (i.e. Dim.1)
```{r}
#Reading in new csv file that has sample info and the Dim.1 and Dim.2 values
PCAindcoor_DarkParams_2023_06_16_site <- read_csv("../PCAindcoor_DarkParams_SigLCHII2023-06-16_site.csv")
str(PCAindcoor_DarkParams_2023_06_16_site)
PCAindcoor_DarkParams_2023_06_16_site$site <- as.factor(PCAindcoor_DarkParams_2023_06_16_site$site)

#Shapiro test
shapiro.test(PCAindcoor_DarkParams_2023_06_16_site$Dim.1)
####passed#### 

#Levene test
leveneTest(Dim.1 ~ site, data=PCAindcoor_DarkParams_2023_06_16_site)
####passed####

#T-test
res_Dim.1 <- t.test(Dim.1 ~ site, data=PCAindcoor_DarkParams_2023_06_16_site, var.equal=T)
res_Dim.1
####Significant####
```

Collectively, the first two principal components accounted for 66.31% of the total variance. The first principal component accounted for 49.76% of the total variance, with Tau1QA, Tau2QA, Tau3QA and PQP_size contributing the largest loadings. Two Sample t-test on the extracted ordination axes for PC1 confirmed differences between isolates (Two Sample t-test, t(17)=3.19, p<0.01).

### Statistical analysis on PC2 (i.e. Dim.2)
```{r}
#Shapiro test
shapiro.test(PCAindcoor_DarkParams_2023_06_16_site$Dim.2)
####Passed####

#Levene test
leveneTest(Dim.2 ~ site, data=PCAindcoor_DarkParams_2023_06_16_site)
####Passed####

#T-test
res_Dim.2 <- t.test(Dim.2 ~ site, data=PCAindcoor_DarkParams_2023_06_16_site, var.equal=T)
res_Dim.2
####Non-significant####
```

The second principal component accounted for 16.55% of the total variance, with TPQ_PSI, QPB_size, Tau3QA and carQ contributing the largest loadings. Two Sample t-test on the extracted ordination axes for PC2 was not able to confirm differences between isolates (Two Sample t-test, t(17)=1.67, p=0.11).

